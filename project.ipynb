{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Co-clustering on Job Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.datasets import make_biclusters\n",
    "from sklearn.datasets import make_checkerboard\n",
    "from sklearn.datasets import samples_generator as sg\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster.bicluster import SpectralCoclustering\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = './apps.tsv'\n",
    "\n",
    "number_of_fold = 5 # for cross validation\n",
    "one_time_run = True # turn it on if we don't want to do 5-fold cross validation which might be slow\n",
    "\n",
    "# config # of cluster\n",
    "min_cluster_num = 2\n",
    "max_cluster_num = 105\n",
    "cluster_num_step = 10\n",
    "\n",
    "# flags to turn on/off algorithms\n",
    "run_kmeans_flag = False\n",
    "run_spectral_coclustering_flag = True\n",
    "run_nmtf_flag = False\n",
    "\n",
    "# enable visualizing clustering result on user-job matrix\n",
    "enable_visualization = True\n",
    "\n",
    "# threshold of popular jobs based # of applications per job,\n",
    "# each of them will generate a user-job matrix with different densities\n",
    "thresholds_popular_jobs = [100, 75] # 100 leads to more dense matrix with less entries, 75 leads to more sparse matrix with more entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(raw_data_path, 'r') as fh:\n",
    "    headers = fh.readline().strip().split('\\t')\n",
    "    content = fh.readlines()\n",
    "raw_apps = [x.rstrip('\\r\\n').split('\\t') for x in content]\n",
    "\n",
    "job_apps_cnt = {}\n",
    "for app in raw_apps:\n",
    "    jobId, memberId = app[-1], app[0]\n",
    "    if jobId in job_apps_cnt:\n",
    "        job_apps_cnt[jobId] = job_apps_cnt[jobId] + 1\n",
    "    else:\n",
    "        job_apps_cnt[jobId] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define method to pick applications for different thresholds of popular jobs and split into train and test sets for k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepross and split applications for k-fold cross validation\n",
    "def create_train_test_set(threshold_popular_jobs, raw_apps, job_apps_cnt):\n",
    "    popular_jobs = set()\n",
    "    for jobId, cnt in job_apps_cnt.items():\n",
    "        if cnt >= threshold_popular_jobs:\n",
    "            popular_jobs.add(jobId)\n",
    "        \n",
    "    #print('# of popular jobs:', len(popular_jobs))\n",
    "\n",
    "    unique_apps = []\n",
    "    for app in raw_apps:\n",
    "            jobId, memberId = app[-1], app[0]\n",
    "            if jobId in popular_jobs:\n",
    "                unique_apps.append((memberId, jobId))\n",
    "\n",
    "    shuffle(unique_apps)\n",
    "    \n",
    "    splats = np.array_split(unique_apps, number_of_fold)\n",
    "\n",
    "    train_set, test_set = {}, {}\n",
    "    for i in range(number_of_fold):\n",
    "        train_set[i] = []\n",
    "        for j in range(number_of_fold):\n",
    "            if i != j:\n",
    "                train_set[i] = train_set[i] + splats[j].tolist()\n",
    "        test_set[i] = splats[i].tolist()\n",
    "    return train_set, test_set, popular_jobs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions to get users, jobs and applications for training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_summary(train_apps, popular_jobs):\n",
    "    train_user = set()\n",
    "    train_job = set()\n",
    "    train_rel = set()\n",
    "    for app in train_apps:\n",
    "        jobId, memberId = app[-1], app[0]\n",
    "        if jobId in popular_jobs:\n",
    "            train_user.add(memberId)\n",
    "            train_job.add(jobId)\n",
    "            train_rel.add((memberId, jobId))\n",
    "    return train_user, train_job, train_rel\n",
    "\n",
    "\n",
    "def get_test_summary(test_apps, train_user, train_job, train_rel):\n",
    "    test_user = set()\n",
    "    test_job = set()\n",
    "    test_rel = set()\n",
    "    for app in test_apps:\n",
    "        jobId, memberId = app[-1], app[0]\n",
    "        # we want to test clustered jobs and users in training set\n",
    "        if jobId in train_job and memberId in train_user:\n",
    "            test_user.add(memberId)\n",
    "            test_job.add(jobId)\n",
    "            # we only consider the applications from testing set which were not used for clustering during training process\n",
    "            if (memberId, jobId) not in train_rel:\n",
    "                test_rel.add((memberId, jobId))\n",
    "    return test_user, test_job, test_rel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some helper methods for prerocessing and building user-job matrix because in the raw data, user and job are respresented by ids so we need to map ids to index before creating user-job matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapUserAndJobToIndex(apps, popular_jobs):\n",
    "    jobIdToIndex = {}\n",
    "    memberIdToIndex = {}\n",
    "    jidx = 0\n",
    "    midx = 0\n",
    "    popular_member_ids = set()\n",
    "    for app in apps:\n",
    "        jobId, memberId = app[-1], app[0]\n",
    "        if jobId in popular_jobs:\n",
    "            popular_member_ids.add(memberId)\n",
    "            if jobId not in jobIdToIndex:\n",
    "                jobIdToIndex[jobId] = jidx\n",
    "                jidx = jidx + 1\n",
    "            if memberId not in memberIdToIndex:\n",
    "                memberIdToIndex[memberId] = midx\n",
    "                midx = midx + 1\n",
    "    return jobIdToIndex, memberIdToIndex, popular_member_ids\n",
    "                \n",
    "def buildUserJobMatrix(apps, user_job_mat, jobIdToIndex, memberIdToIndex):\n",
    "    member_apps = {} # store jobs each member has applied\n",
    "    for app in apps:\n",
    "        jobId, memberId = app[-1], app[0]\n",
    "        if jobId in jobIdToIndex:\n",
    "            midx = memberIdToIndex[memberId]\n",
    "            jidx = jobIdToIndex[jobId]\n",
    "            user_job_mat[memberIdToIndex[memberId]][jobIdToIndex[jobId]] = 1\n",
    "            if midx in member_apps:\n",
    "                member_apps.get(midx).add(jidx)\n",
    "            else:\n",
    "                new_app_set = set()\n",
    "                new_app_set.add(jidx)\n",
    "                member_apps[midx] = new_app_set\n",
    "    print('user-job matrix size:', user_job_mat.shape)\n",
    "    return user_job_mat, member_apps\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define validation method for K-means and NMTF(because this co-clustering method doesn't tell which row cluster corresponds to which column cluster as it requires to set # of row and column clusters separately) to generate metrics.\n",
    "\n",
    "#### True Positive: a user applies to a job in testing set and they are in the same trained cluster.\n",
    "#### True Negative: a user doesn't apply to a job in testing set and they are in the different trained clusters.\n",
    "#### False Positive: a user doesn't apply to a job in testing set but they are in the same trained cluster.\n",
    "#### False Negative: a user applies to a job in testing set but they are in the different trained clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateKmeansOrNMTF(test_user, test_job, test_rel, user_cluster_map, clusters_index_map, member_apps, memberIdToIndex, jobIdToIndex):\n",
    "    cluster_jobs = {}\n",
    "    # cluster the jobs that are applied by the users in the same user cluster\n",
    "    for label in clusters_index_map:\n",
    "        m_indices = clusters_index_map.get(label)\n",
    "        jobs = set()\n",
    "        for midx in m_indices:\n",
    "            # get jobs for each member in cluster\n",
    "            jobs = jobs.union(member_apps[midx])\n",
    "        cluster_jobs[label] = jobs \n",
    "        \n",
    "    TP, FN = 0, 0\n",
    "    for (memberId, jobId) in test_rel:\n",
    "        midx = memberIdToIndex[memberId]\n",
    "        jidx = jobIdToIndex[jobId]\n",
    "        if midx in user_cluster_map:\n",
    "            label = user_cluster_map[midx]\n",
    "            if jidx in cluster_jobs[label]:\n",
    "                TP = TP + 1\n",
    "            else:\n",
    "                FN = FN + 1\n",
    "                \n",
    "    TN, FP = 0, 0\n",
    "    for memberId in test_user:\n",
    "        for jobId in test_job:\n",
    "            if (memberId, jobId) not in test_rel:\n",
    "                midx = memberIdToIndex[memberId]\n",
    "                jidx = jobIdToIndex[jobId]\n",
    "                if midx in user_cluster_map:\n",
    "                    label = user_cluster_map[midx]\n",
    "                    if jidx in cluster_jobs[label]:\n",
    "                        FP = FP + 1\n",
    "                    else:\n",
    "                        TN = TN + 1\n",
    "                \n",
    "    if TP == 0 and FN == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = TP * 1.0 / (TP +FN)\n",
    "    \n",
    "    pre = TP * 1.0 / (TP + FP)\n",
    "    recall = TP * 1.0 / (TP +FN)\n",
    "    F1 = 2.0 * pre * recall /(pre +recall)\n",
    "    accuracy = (TP + TN) * 1.0 /(TP + TN + FP + FN)\n",
    "    \n",
    "    print('Validation precision, recall, F1, accuracy', pre, recall, F1, accuracy)\n",
    "   \n",
    "    return recall, F1, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define method for K-means including training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans(train_set, test_set, popular_jobs):\n",
    "    print('Start running K-means')\n",
    "    recall_map = {}\n",
    "    f1_map = {}\n",
    "    accuracy_map = {}\n",
    "    for clusters_cnt in xrange(min_cluster_num, max_cluster_num, cluster_num_step):\n",
    "        print('Clustering with cluster count:', clusters_cnt)\n",
    "        \n",
    "        experiment_cnt = number_of_fold if not one_time_run else 1\n",
    "            \n",
    "        recalls = [0] * experiment_cnt\n",
    "        f1s = [0] * experiment_cnt\n",
    "        accuracies = [0] * experiment_cnt\n",
    "\n",
    "        for fold in range(experiment_cnt):\n",
    "            apps = train_set[fold]\n",
    "            jobIdToIndex, memberIdToIndex, popular_member_ids = mapUserAndJobToIndex(apps, popular_jobs)\n",
    "            user_job_mat = np.zeros((len(popular_member_ids), len(jobIdToIndex)))\n",
    "            user_job_mat, member_apps = buildUserJobMatrix(apps, user_job_mat, jobIdToIndex, memberIdToIndex)\n",
    "\n",
    "            est = KMeans(n_clusters=clusters_cnt)\n",
    "            est.fit(user_job_mat)\n",
    "            labels = est.labels_\n",
    "\n",
    "            clusters_index_map = {} # cluster label -> user index\n",
    "            user_cluster_map = {} # user index -> cluster label\n",
    "            for i, label in enumerate(labels):\n",
    "                user_cluster_map[i] = label\n",
    "                if label in clusters_index_map:\n",
    "                    clusters_index_map[label].append(i)\n",
    "                else:\n",
    "                    clusters_index_map[label] = [i]\n",
    "\n",
    "            if enable_visualization:\n",
    "                # just for coloring\n",
    "                for label in range(clusters_cnt):\n",
    "                    for i in clusters_index_map[label]:\n",
    "                        user_job_mat[i] = user_job_mat[i] * (label + 1)\n",
    "\n",
    "                # group users in same cluster together\n",
    "                sorted_user_job_mat = user_job_mat[np.argsort(labels)]\n",
    "\n",
    "                plt.figure(figsize = (5, 5))\n",
    "                plt.ylabel('Users')\n",
    "                plt.xlabel('Jobs')\n",
    "                cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\", \"red\",\"violet\",\"blue\"])\n",
    "                plt.imshow(sorted_user_job_mat, cmap=cmap, aspect=user_job_mat.shape[1] * 1.0 / user_job_mat.shape[0])\n",
    "                plt.show()\n",
    "\n",
    "            train_user, train_job, train_rel = get_train_summary(apps, popular_jobs)\n",
    "            test_apps = test_set[fold]\n",
    "            test_user, test_job, test_rel = get_test_summary(test_apps, train_user, train_job, train_rel)\n",
    "            recalls[fold], f1s[fold], accuracies[fold] = validateKmeansOrNMTF(test_user, test_job, test_rel, user_cluster_map, clusters_index_map, member_apps, memberIdToIndex, jobIdToIndex)\n",
    "\n",
    "        recall_map[clusters_cnt] = np.mean(recalls)\n",
    "        f1_map[clusters_cnt] = np.mean(f1s)\n",
    "        accuracy_map[clusters_cnt] = np.mean(accuracies)\n",
    "    print('Average recall, f1 and accuracy for each number of clusters:', recall_map, f1_map, accuracy_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement nmtf and define method for nmtf (Orthogonal nonnegative matrix t-factorizations for clustering) including training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nmtf(X, k, l, num_iter=50, debug_mode=True):\n",
    "    print('Start running iterations for nmtf')\n",
    "    m, n = X.shape\n",
    "    est = KMeans(n_clusters=k)\n",
    "    est.fit(X)\n",
    "    V = est.cluster_centers_.T\n",
    "    #print('inital V ', V)\n",
    "    V = V\n",
    "    est = KMeans(n_clusters=l)\n",
    "    est.fit(X.T)\n",
    "    U = est.cluster_centers_.T\n",
    "    #print('inital U ', U)\n",
    "    S = U.T.dot(X).dot(V)\n",
    "\n",
    "    error_best = np.inf\n",
    "    error = error_best\n",
    "\n",
    "    for i in xrange(num_iter):\n",
    "        # solve subproblem to update V\n",
    "        V = V * (X.T.dot(U).dot(S) / V.dot(V.T).dot(X.T).dot(U).dot(S))\n",
    "\n",
    "        # solve subproblem to update U\n",
    "        test1 = U.dot(U.T).dot(X).dot(V).dot(S.T)\n",
    "        if np.isnan(test1).any():\n",
    "            print('solve U', U, S, V, X)\n",
    "            break\n",
    "        U = U * (X.dot(V).dot(S.T) / test1)\n",
    "\n",
    "        # solve subproblem to update S\n",
    "        S = S * (U.T.dot(X).dot(V) / U.T.dot(U).dot(S).dot(V.T).dot(V))\n",
    "        \n",
    "        error_ant = error\n",
    "        error = np.sum((X - U.dot(S).dot(V.T)) ** 2)\n",
    "\n",
    "        if error < error_best:\n",
    "            U_best = U\n",
    "            S_best = S\n",
    "            V_best = V\n",
    "            error_best = error\n",
    "\n",
    "        if debug_mode:\n",
    "            print('Iteration No. and current error:', i, error)\n",
    "        if np.abs(error - error_ant) <= 0.001:\n",
    "            break\n",
    "\n",
    "    rows_ind = np.argmax(U_best, axis=1)\n",
    "    cols_ind = np.argmax(V_best, axis=1)\n",
    "\n",
    "    return U_best, S_best, V_best.T, rows_ind, cols_ind, error_best\n",
    "\n",
    "\n",
    "def run_nmtf(train_set, test_set, popular_jobs):\n",
    "    print('Start running NMTF for co-clustering')\n",
    "    recall_map = {}\n",
    "    f1_map = {}\n",
    "    accuracy_map = {}\n",
    "    for clusters_cnt in xrange(min_cluster_num, max_cluster_num, cluster_num_step):\n",
    "        print('Clustering with cluster count:', clusters_cnt)\n",
    "        \n",
    "        experiment_cnt = number_of_fold if not one_time_run else 1\n",
    "            \n",
    "        recalls = [0] * experiment_cnt\n",
    "        f1s = [0] * experiment_cnt\n",
    "        accuracies = [0] * experiment_cnt\n",
    "\n",
    "        for fold in range(experiment_cnt):\n",
    "            apps = train_set[fold]\n",
    "            jobIdToIndex, memberIdToIndex, popular_member_ids = mapUserAndJobToIndex(apps, popular_jobs)\n",
    "            \n",
    "            user_job_mat = np.zeros((len(popular_member_ids), len(jobIdToIndex)))\n",
    "             # initialize to 0.01 to avoid devide by zero issue when running NMTF, it won't affect the result\n",
    "            for row in range(len(popular_member_ids)):\n",
    "                for col in range(len(jobIdToIndex)):\n",
    "                    user_job_mat[row][col] = 0.01\n",
    "            \n",
    "            user_job_mat, member_apps = buildUserJobMatrix(apps, user_job_mat, jobIdToIndex, memberIdToIndex)\n",
    "\n",
    "            # normally row cluster number equals to column cluster number\n",
    "            U_best, S_best, V_best, rows_ind, cols_ind, error_best = nmtf(user_job_mat, clusters_cnt, clusters_cnt)\n",
    "            labels = rows_ind\n",
    "            clusters_index_map = {}\n",
    "            user_cluster_map = {}\n",
    "            for i, label in enumerate(labels):\n",
    "                user_cluster_map[i] = label\n",
    "                if label in clusters_index_map:\n",
    "                    clusters_index_map[label].append(i)\n",
    "                else:\n",
    "                    clusters_index_map[label] = [i]\n",
    "\n",
    "            if enable_visualization:\n",
    "                fit_data = user_job_mat[np.argsort(rows_ind)]\n",
    "                fit_data = fit_data[:, np.argsort(cols_ind)]\n",
    "                \n",
    "                # find cluster separation coordinates on x and y axis\n",
    "                rows_sep = set()\n",
    "                cols_sep = set()\n",
    "                sorted_rows_ind = np.sort(rows_ind) \n",
    "                sorted_cols_ind = np.sort(cols_ind)\n",
    "                for i in range(rows_ind.shape[0]):\n",
    "                    if i != 0 and sorted_rows_ind[i] != sorted_rows_ind[i-1]:\n",
    "                        rows_sep.add(i)\n",
    "                for i in range(cols_ind.shape[0]):\n",
    "                    if i != 0 and sorted_cols_ind[i] != sorted_cols_ind[i-1]:\n",
    "                        cols_sep.add(i)\n",
    "\n",
    "                cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\", \"blue\"])\n",
    "\n",
    "                plt.figure(figsize = (8, 8))\n",
    "                plt.ylabel('Users')\n",
    "                plt.xlabel('Jobs')\n",
    "                plt.imshow(fit_data, cmap=cmap, aspect=user_job_mat.shape[1] * 1.0 / user_job_mat.shape[0])\n",
    "                \n",
    "                # draw cluster separation lines\n",
    "                for row_sep in rows_sep:\n",
    "                    plt.axhline(y = row_sep, linewidth=1, color='r')\n",
    "                for col_sep in cols_sep:\n",
    "                    plt.axvline(x = col_sep, linewidth=1, color='r')\n",
    "                plt.show()\n",
    "\n",
    "            train_user, train_job, train_rel = get_train_summary(apps, popular_jobs)\n",
    "            test_apps = test_set[fold]\n",
    "            test_user, test_job, test_rel = get_test_summary(test_apps, train_user, train_job, train_rel)\n",
    "            recalls[fold], f1s[fold], accuracies[fold] = validateKmeansOrNMTF(test_user, test_job, test_rel, user_cluster_map, clusters_index_map, member_apps, memberIdToIndex, jobIdToIndex)\n",
    "\n",
    "\n",
    "        recall_map[clusters_cnt] = np.mean(recalls)\n",
    "        f1_map[clusters_cnt] = np.mean(f1s)\n",
    "        accuracy_map[clusters_cnt] = np.mean(accuracies)\n",
    "    print('Average recall, f1 and accuracy for each number of clusters:', recall_map, f1_map, accuracy_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define validation method for spectral co-clustering (Co-clustering documents and words using Bipartite Spectral Graph Partitioning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate spectral co-clustering\n",
    "def validateSpectralCoClustering(test_user, test_job, test_rel, user_cluster_map, job_cluster_map, memberIdToIndex, jobIdToIndex):\n",
    "    TP, FN = 0, 0\n",
    "    cluster_dist = {}\n",
    "    true_dist = {}\n",
    "    for (memberId, jobId) in test_rel:\n",
    "        midx = memberIdToIndex[memberId]\n",
    "        jidx = jobIdToIndex[jobId] \n",
    "        if midx in user_cluster_map and jidx in job_cluster_map:\n",
    "            true_cluster = user_cluster_map[midx]\n",
    "            if true_cluster in true_dist:\n",
    "                true_dist[true_cluster] = true_dist[true_cluster] + 1\n",
    "            else:\n",
    "                true_dist[true_cluster] = 1\n",
    "                \n",
    "            if user_cluster_map[midx] == job_cluster_map[jidx]:\n",
    "                TP = TP + 1\n",
    "                cluster = user_cluster_map[midx]\n",
    "                if cluster in cluster_dist:\n",
    "                    cluster_dist[cluster] = cluster_dist[cluster] + 1\n",
    "                else:\n",
    "                    cluster_dist[cluster] = 1\n",
    "            else:\n",
    "                FN = FN + 1\n",
    "    #print('test data cluster and true dist:', cluster_dist, true_dist)\n",
    "    TN, FP = 0, 0\n",
    "    for memberId in test_user:\n",
    "        for jobId in test_job:\n",
    "            if (memberId, jobId) not in test_rel:\n",
    "                midx = memberIdToIndex[memberId]\n",
    "                jidx = jobIdToIndex[jobId]\n",
    "                if midx in user_cluster_map and jidx in job_cluster_map:\n",
    "                    if user_cluster_map[midx] == job_cluster_map[jidx]:\n",
    "                        FP = FP + 1\n",
    "                    else:\n",
    "                        TN = TN + 1\n",
    "                        \n",
    "    print('TP:', TP)\n",
    "    pre = TP * 1.0 / (TP + FP)\n",
    "    recall = TP * 1.0 / (TP +FN)\n",
    "    F1 = 2.0 * pre * recall /(pre +recall)\n",
    "    accuracy = (TP + TN) * 1.0 /(TP + TN + FP + FN)\n",
    "    print('test data precision, recall, F1, accuracy', pre, recall, F1, accuracy)\n",
    "  \n",
    "    return recall, F1, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define method to compute the average silhouette score of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSilhouetteScore(member_apps, model, inverted_user_cluster_map, inverted_job_cluster_map):\n",
    "    member_cnt = len(member_apps)\n",
    "    score_dis_in_cluster = np.zeros(member_cnt) # disimilarity for each user within a cluster\n",
    "    for i in member_apps:\n",
    "        label = model.row_labels_[i]\n",
    "        if label in inverted_job_cluster_map:\n",
    "            jobs_in_cluster = inverted_job_cluster_map.get(label)\n",
    "            app_in_cluster = len(jobs_in_cluster.intersection(member_apps.get(i)))\n",
    "        else:\n",
    "            app_in_cluster = 0\n",
    "        total_app = len(member_apps.get(i))\n",
    "        score_dis_in_cluster[i] = 1 -  app_in_cluster /total_app\n",
    "\n",
    "    score_dis_out_cluster = np.zeros(member_cnt) # disimilarity for each user with different clusters\n",
    "    for i in member_apps:\n",
    "        total_app = len(member_apps.get(i))\n",
    "        b = -1 #disimilarity with one cluster\n",
    "        for label in inverted_job_cluster_map:\n",
    "            if label != model.row_labels_[i]:\n",
    "                jobs_in_cluster = inverted_job_cluster_map.get(label)\n",
    "                app_in_cluster = len(jobs_in_cluster.intersection(member_apps.get(i)))\n",
    "                b_per_label = 1 -  app_in_cluster /total_app\n",
    "                if b == -1 or b_per_label < b:\n",
    "                    b = b_per_label\n",
    "        score_dis_out_cluster[i] = b # minimum dismilarity with different clusters\n",
    "\n",
    "    s_score = {}\n",
    "    cluster_score = {} # cluster silhouette score equals to the average silhouette score of users in the cluster\n",
    "    total_s_score = 0 # total cluster silhouette scores\n",
    "    for label in inverted_user_cluster_map:\n",
    "        members_in_cluster = inverted_user_cluster_map.get(label)\n",
    "        score = 0\n",
    "        for i in  members_in_cluster:\n",
    "            b = score_dis_out_cluster[i]\n",
    "            a = score_dis_in_cluster[i]\n",
    "            s_score[i] = (b - a) / max(a, b)\n",
    "            score = score + s_score[i]\n",
    "        cluster_score[label] = score / len(members_in_cluster)\n",
    "        total_s_score = total_s_score + cluster_score[label]\n",
    "    return total_s_score/len(cluster_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define methods to train and test using Spectral Co-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_spectral_coclustering(train_set, test_set, popular_jobs):\n",
    "    print('Start running Spectral Co-clustering')\n",
    "    recall_map = {}\n",
    "    f1_map = {}\n",
    "    accuracy_map = {}\n",
    "    s_score_map = {} # silhouette score\n",
    "    for clusters_cnt in xrange(min_cluster_num, max_cluster_num, cluster_num_step):\n",
    "        print('Clustering with cluster count:', clusters_cnt)\n",
    "        \n",
    "        experiment_cnt = number_of_fold if not one_time_run else 1\n",
    "            \n",
    "        recalls = [0] * experiment_cnt\n",
    "        f1s = [0] * experiment_cnt\n",
    "        accuracies = [0] * experiment_cnt\n",
    "        s_scores = [0] * experiment_cnt\n",
    "        for fold in range(experiment_cnt):\n",
    "            apps = train_set[fold]\n",
    "            jobIdToIndex, memberIdToIndex, popular_member_ids = mapUserAndJobToIndex(apps, popular_jobs)\n",
    "            user_job_mat = np.zeros((len(popular_member_ids), len(jobIdToIndex)))\n",
    "            user_job_mat, member_apps = buildUserJobMatrix(apps, user_job_mat, jobIdToIndex, memberIdToIndex)\n",
    "\n",
    "            model = SpectralCoclustering(n_clusters=clusters_cnt, random_state=0)\n",
    "            model.fit(user_job_mat)\n",
    "\n",
    "            labels = model.row_labels_\n",
    "            user_cluster_map = {}\n",
    "            inverted_user_cluster_map = {}\n",
    "            for i, label in enumerate(labels):\n",
    "                user_cluster_map[i] = label\n",
    "                if label in inverted_user_cluster_map:\n",
    "                    inverted_user_cluster_map[label].add(i)\n",
    "                else:\n",
    "                    new_set = set()\n",
    "                    new_set.add(i)\n",
    "                    inverted_user_cluster_map[label] = new_set\n",
    "\n",
    "            labels = model.column_labels_\n",
    "            job_cluster_map = {}\n",
    "            inverted_job_cluster_map = {}\n",
    "            for i, label in enumerate(labels):\n",
    "                job_cluster_map[i] = label\n",
    "                if label in inverted_job_cluster_map:\n",
    "                    inverted_job_cluster_map[label].add(i)\n",
    "                else:\n",
    "                    new_set = set()\n",
    "                    new_set.add(i)\n",
    "                    inverted_job_cluster_map[label] = new_set\n",
    "                    \n",
    "            if enable_visualization:\n",
    "                colored_fit_data = np.copy(user_job_mat)\n",
    "                # coloring original user-job matrix\n",
    "                for label in range(clusters_cnt):\n",
    "                    if label in inverted_user_cluster_map and label in inverted_job_cluster_map:\n",
    "                        for i in inverted_user_cluster_map[label]:\n",
    "                            for j in inverted_job_cluster_map[label]:\n",
    "                               colored_fit_data[i][j] = colored_fit_data[i][j] * (label + 1)\n",
    "\n",
    "                colored_fit_data = colored_fit_data[np.argsort(model.row_labels_)]\n",
    "                colored_fit_data = colored_fit_data[:, np.argsort(model.column_labels_)]\n",
    "\n",
    "                cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\", \"red\",\"violet\",\"blue\"])\n",
    "                plt.figure(figsize = (7, 7))\n",
    "                plt.ylabel('Users')\n",
    "                plt.xlabel('Jobs')\n",
    "                plt.imshow(colored_fit_data, cmap=cmap, aspect=user_job_mat.shape[1] * 1.0 / user_job_mat.shape[0])\n",
    "                plt.show()\n",
    "        \n",
    "            \n",
    "            train_user, train_job, train_rel = get_train_summary(apps, popular_jobs)\n",
    "            test_apps = test_set[fold]\n",
    "            test_user, test_job, test_rel = get_test_summary(test_apps, train_user, train_job, train_rel)\n",
    "            recalls[fold], f1s[fold], accuracies[fold] = validateSpectralCoClustering(test_user, test_job, test_rel, user_cluster_map, job_cluster_map, memberIdToIndex, jobIdToIndex)\n",
    "            s_scores[fold] = getSilhouetteScore(member_apps, model, inverted_user_cluster_map, inverted_job_cluster_map)\n",
    "\n",
    "        recall_map[clusters_cnt] = np.mean(recalls)\n",
    "        f1_map[clusters_cnt] = np.mean(f1s)\n",
    "        accuracy_map[clusters_cnt] = np.mean(accuracies)\n",
    "        s_score_map[clusters_cnt] = np.mean(s_scores)\n",
    "    print('Average recall, f1, accuracy and silhouette score for each number of clusters:', recall_map, f1_map, accuracy_map, s_score_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run k-means, nmtf and spectral co-clustering on two dataset with different densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold_popular_jobs in thresholds_popular_jobs:\n",
    "    train_sets, test_sets, popular_jobs = create_train_test_set(threshold_popular_jobs, raw_apps, job_apps_cnt)\n",
    "    \n",
    "    if run_kmeans_flag:\n",
    "        run_kmeans(train_sets, test_sets, popular_jobs)\n",
    "    if run_spectral_coclustering_flag:\n",
    "        run_spectral_coclustering(train_sets, test_sets, popular_jobs)\n",
    "    if run_nmtf_flag:\n",
    "        run_nmtf(train_sets, test_sets, popular_jobs)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
